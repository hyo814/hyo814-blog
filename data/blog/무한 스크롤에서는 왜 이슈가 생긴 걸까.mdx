---
title: 무한 스크롤에서는 왜 이슈가 생긴 걸까?
date: '2024-09-29'
tags: [무한스크롤]
draft: false
summary: '무한스크롤'
---

# 무한 스크롤에서는 왜 이슈가 생긴 걸까?

### 1. **useSWR 사용 이유**

useSWR을 사용한 이유가 **데이터 캐싱**과 **패칭**을 효율적으로 처리하기 위함이라면, 이는 적절한 선택입니다. 특히 무한 스크롤에서 데이터를 페이지 단위로 불러오면서, 이미 패칭한 데이터를 캐시에 저장해 불필요한 네트워크 요청을 줄일 수 있다는 장점이 있습니다.

### 2. **데이터 정제와 누락된 API 문제**

백엔드에서 제공하는 API가 누락되었거나, 필요한 데이터를 제대로 보내지 않는 경우라면, **백엔드 팀과 협의하여 API를 수정**하는 것이 우선시 되어야 합니다. 그러나 무한 스크롤 구현에서 불가피하게 프론트엔드에서 데이터를 처리해야 하는 상황이 생길 수 있습니다.

### 3. **무한 스크롤 이슈**

무한 스크롤에서 70% 뷰일 때 계속해서 데이터를 요청하는 이슈는 **스크롤 이벤트 처리 로직**에 문제가 있거나, **페이지네이션 혹은 데이터 페칭 조건**을 제대로 설정하지 않았을 수 있습니다. 이 경우 아래와 같은 방법으로 해결할 수 있습니다:

- **Intersection Observer API**를 활용하여, 사용자가 화면에서 마지막 요소에 가까워질 때만 새로운 데이터를 요청하는 방식으로 개선.
- **throttle** 혹은 **debounce**를 적용해 스크롤 이벤트가 과도하게 발생하지 않도록 제어.
- 이미 요청된 데이터 범위를 추적하고, 동일한 데이터를 중복으로 요청하지 않도록 처리.

### 4. **프론트엔드에서의 데이터 정제는 언제 필요한가?**

프론트엔드에서의 데이터 정제는 **백엔드에서 제대로 된 데이터를 제공하지 못할 경우**에 한해서만 이뤄져야 합니다. 예를 들어, 누락된 데이터를 백엔드에서 보완할 수 없다면, 프론트엔드에서 데이터를 필터링하거나 가공하는 작업을 할 수 있습니다. 하지만 이 또한 임시방편일 뿐, 최종적으로는 백엔드에서 문제를 해결하는 것이 장기적으로 옳은 접근입니다.

### 결론적으로:

- **useSWR**은 캐싱과 데이터 패칭에 효율적이지만, 백엔드에서 데이터 누락 문제가 있다면 **백엔드와 협업하여 해결**하는 것이 우선.
- 무한 스크롤에서의 데이터 패칭 이슈는 **스크롤 이벤트 처리**와 **페칭 조건을 재검토**해 해결할 필요가 있음.

---

### 1. **백엔드와 프론트엔드의 역할 분리**

무한 스크롤에서 발생하는 **데이터 패칭 이슈**는 **프론트엔드에서 주로 해결**해야 할 문제입니다. 이유는, 사용자가 페이지를 스크롤할 때 **언제 데이터를 요청할지** 결정하는 것은 프론트엔드 로직에 해당하기 때문입니다. 즉, 프론트엔드가 스크롤 이벤트를 감지하고 데이터를 패칭하는 시점을 결정하는 데 있어서, 적절한 제어가 필요합니다.

면접관의 질문이 백엔드에서 해결해야 하지 않냐는 것은 아마도 **과도한 요청**이 서버에 부담을 줄 수 있기 때문일 것입니다. 그러나 실제로 데이터를 **언제 패칭할지**와 같은 문제는 **프론트엔드 로직**으로 해결할 수 있습니다.

### 2. **데이터 패칭과 캐싱**

`useSWR`을 사용하는 이유는 **캐싱과 패칭을 효율적으로 관리**하기 위해서입니다. 즉, 이미 불러온 데이터를 캐시해 두면 **중복된 데이터 요청을 방지**하고, 성능을 최적화할 수 있습니다. 이 점을 강조할 수 있습니다. 프론트엔드가 무한히 반복적으로 API를 호출하지 않도록 **캐싱과 무효화 로직**을 통해 불필요한 요청을 줄이는 것이 핵심입니다.

### 3. **프론트엔드에서 해결할 수 있는 부분**

면접관이 제시한 문제는 백엔드에서 고쳐야 한다는 시각일 수 있지만, 무한 스크롤의 데이터 페칭 이슈는 다음과 같은 방법으로 프론트엔드에서 충분히 제어할 수 있습니다:

- **Intersection Observer API**로 **마지막 요소에 도달할 때**만 데이터를 요청. 이를 통해 불필요한 요청을 방지할 수 있습니다.
- **Throttle/Debounce**를 사용하여 스크롤 이벤트가 과도하게 발생하지 않도록 제어. 이는 데이터 요청 빈도를 줄여서 서버에 과부하를 방지합니다.
- **useSWR**의 캐싱 기능을 사용하여 이미 로드된 데이터를 중복 요청하지 않도록 제어.

### 4. **백엔드가 처리해야 하는 부분**

백엔드가 처리해야 하는 문제는 주로 **대량의 데이터가 적절하게 페이지 단위로 나누어 제공되고 있는지**와 관련이 있습니다. 무한 스크롤의 경우, 백엔드가 데이터를 페이지 단위로 잘 나누어 제공해야 하며, **API 응답 시간**도 최적화되어야 합니다. 하지만, **무한 스크롤이 무한 반복적으로 API를 호출하는 문제는 프론트엔드에서 발생하는 문제**로, 이를 적절히 제어하는 것은 프론트엔드의 역할입니다.

> "무한 스크롤에서 반복적으로 API를 호출하는 이슈는 프론트엔드에서 스크롤 이벤트를 어떻게 처리하는지에 따라 발생하는 문제입니다. 이를 해결하기 위해 저는 useSWR을 사용하여 캐싱과 데이터 패칭을 최적화했고, Intersection Observer API와 같은 기술을 활용하여 불필요한 데이터 요청을 방지할 수 있도록 했습니다. 백엔드가 과부하되지 않도록 데이터가 적절히 페이지 단위로 제공되어야 하지만, 실제로 언제 데이터를 요청할지 제어하는 것은 프론트엔드의 역할입니다."

---

React에서 데이터 패칭 및 캐싱을 효율적으로 처리할 수 있는 방법은 **React Query** 외에도 여러 가지가 있습니다. 각 방법마다 장단점이 있으니, 필요에 따라 적절한 선택이 가능합니다. 여기 몇 가지 대안을 소개하겠습니다:

### 1. **SWR (Stale-While-Revalidate)**

이미 사용 중인 `SWR`은 **React Query**와 매우 유사하지만, 더 가볍고 간단한 사용법을 제공합니다. 특히 데이터를 **캐싱**하고, **자동으로 데이터를 다시 가져오거나(revalidate)**, **캐시된 데이터를 먼저 보여주는 기능**에서 장점이 있습니다. 효율적인 데이터 패칭 및 캐싱을 위해 계속 사용할 수 있습니다.

**장점**:

- 사용이 간단하고 설정이 적음.
- `React Query`보다 경량화된 느낌.
- GitHub에서 페이스북팀이 유지보수하는 **Next.js**와 잘 호환됨.

### 2. **Axios or Fetch with Custom Hooks**

`axios`나 `fetch`와 같은 기본적인 데이터 패칭 라이브러리를 **커스텀 훅**과 함께 사용할 수 있습니다. 이를 통해 간단하게 데이터를 가져오고, 캐시 로직이나 재시도 로직을 스스로 구현할 수 있습니다.

```jsx
import { useState, useEffect } from 'react'
import axios from 'axios'

function useFetchData(url) {
  const [data, setData] = useState(null)
  const [loading, setLoading] = useState(true)
  const [error, setError] = useState(null)

  useEffect(() => {
    const fetchData = async () => {
      try {
        const response = await axios.get(url)
        setData(response.data)
      } catch (error) {
        setError(error)
      } finally {
        setLoading(false)
      }
    }

    fetchData()
  }, [url])

  return { data, loading, error }
}

export default useFetchData
```

**장점**:

- 직접 데이터 요청 로직을 커스터마이징할 수 있음.
- 외부 라이브러리에 대한 의존성을 줄일 수 있음.

**단점**:

- 데이터 캐싱, 무효화, 패칭 최적화 등 추가 기능을 직접 구현해야 함.
- 복잡한 로직이 필요한 경우 관리가 어려움.

### 3. **Apollo Client (GraphQL)**

만약 **GraphQL**을 사용하는 프로젝트라면, `Apollo Client`가 훌륭한 선택입니다. Apollo는 **캐싱**과 **데이터 관리**에 있어 매우 강력한 도구입니다. 특히 서버의 데이터와 클라이언트 상태를 자동으로 동기화해주는 기능이 있어 무한 스크롤 같은 상황에서 효율적인 데이터 관리가 가능합니다.

```jsx
import { useQuery, gql } from '@apollo/client'

const GET_ITEMS = gql`
  query GetItems($limit: Int!, $offset: Int!) {
    items(limit: $limit, offset: $offset) {
      id
      name
    }
  }
`

function MyComponent() {
  const { loading, error, data } = useQuery(GET_ITEMS, {
    variables: { limit: 10, offset: 0 },
  })

  if (loading) return <p>Loading...</p>
  if (error) return <p>Error :(</p>

  return data.items.map(({ id, name }) => (
    <div key={id}>
      <p>{name}</p>
    </div>
  ))
}
```

**장점**:

- GraphQL과의 자연스러운 연동.
- 캐싱, 데이터 패칭, 상태 관리 등 다양한 기능을 기본 제공.
- 데이터 페칭 로직이 간결함.

**단점**:

- GraphQL API가 필요함.
- REST API보다 GraphQL 학습 비용이 있을 수 있음.

### 4. **Redux Toolkit (RTK Query)**

Redux를 사용 중이라면, `Redux Toolkit`에서 제공하는 **RTK Query**를 사용할 수 있습니다. 이는 Redux의 표준 데이터 패칭 및 캐싱 솔루션으로, React Query와 비슷한 기능을 제공합니다. 특히 Redux와 함께 상태 관리를 자연스럽게 연결할 수 있는 장점이 있습니다.

```jsx
import { createApi, fetchBaseQuery } from '@reduxjs/toolkit/query/react'

const apiSlice = createApi({
  reducerPath: 'api',
  baseQuery: fetchBaseQuery({ baseUrl: '/api' }),
  endpoints: (builder) => ({
    getItems: builder.query({
      query: (page) => `items?page=${page}`,
    }),
  }),
})

export const { useGetItemsQuery } = apiSlice
```

**장점**:

- Redux 상태 관리와 통합된 데이터 패칭.
- Redux를 사용하는 프로젝트에서 자연스러운 선택.
- 서버 상태와 클라이언트 상태를 일관되게 관리 가능.

**단점**:

- Redux 학습이 필요하며, 기존 Redux 도입이 전제됨.
- React Query나 SWR보다 약간 더 복잡할 수 있음.

### 5. **Firebase with Firestore**

만약 실시간 데이터와 연동되는 서비스라면 **Firebase Firestore**를 사용해 데이터를 실시간으로 구독하고 캐시할 수 있습니다. 특히 무한 스크롤과 같은 대량의 데이터를 실시간으로 받아와야 할 때 유용할 수 있습니다.

**장점**:

- 실시간 데이터 동기화 가능.
- 복잡한 서버 로직 없이 간단하게 데이터베이스와 통합 가능.

**단점**:

- Firebase 학습이 필요함.
- 특정 서비스에 의존하게 됨.
